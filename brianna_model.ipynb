{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-77eed96404e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Python's OS Package\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "# Usual imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "\n",
    "# Python's OS Package\n",
    "import os\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# nltk imports\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nov2.1_df.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sia_positive</th>\n",
       "      <th>sia_negative</th>\n",
       "      <th>sia_neutral</th>\n",
       "      <th>sia_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @JulianCastro: My grandmother was a domesti...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MayorOfLA: #GettyFire update | 8AM:\\n\\n- 5...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Getty Fire Ignited by Power Line in Sepulveda ...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @latimes: In an ominous new warning, the Na...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arson investigators from the Los Angeles Fire ...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  RT @JulianCastro: My grandmother was a domesti...   \n",
       "1       1  RT @MayorOfLA: #GettyFire update | 8AM:\\n\\n- 5...   \n",
       "2       1  Getty Fire Ignited by Power Line in Sepulveda ...   \n",
       "3       1  RT @latimes: In an ominous new warning, the Na...   \n",
       "4       1  Arson investigators from the Los Angeles Fire ...   \n",
       "\n",
       "               time  sia_positive  sia_negative  sia_neutral  sia_compound  \n",
       "0  10/29/2019 22:56         0.000         0.000        1.000        0.0000  \n",
       "1  10/29/2019 22:56         0.000         0.000        1.000        0.0000  \n",
       "2  10/29/2019 22:56         0.000         0.211        0.789       -0.3400  \n",
       "3  10/29/2019 22:56         0.000         0.202        0.798       -0.5859  \n",
       "4  10/29/2019 22:56         0.066         0.122        0.812       -0.2732  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sia_positive</th>\n",
       "      <th>sia_negative</th>\n",
       "      <th>sia_neutral</th>\n",
       "      <th>sia_compound</th>\n",
       "      <th>mention</th>\n",
       "      <th>https</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @JulianCastro: My grandmother was a domesti...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MayorOfLA: #GettyFire update | 8AM:\\n\\n- 5...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Getty Fire Ignited by Power Line in Sepulveda ...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @latimes: In an ominous new warning, the Na...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arson investigators from the Los Angeles Fire ...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  RT @JulianCastro: My grandmother was a domesti...   \n",
       "1       1  RT @MayorOfLA: #GettyFire update | 8AM:\\n\\n- 5...   \n",
       "2       1  Getty Fire Ignited by Power Line in Sepulveda ...   \n",
       "3       1  RT @latimes: In an ominous new warning, the Na...   \n",
       "4       1  Arson investigators from the Los Angeles Fire ...   \n",
       "\n",
       "               time  sia_positive  sia_negative  sia_neutral  sia_compound  \\\n",
       "0  10/29/2019 22:56         0.000         0.000        1.000        0.0000   \n",
       "1  10/29/2019 22:56         0.000         0.000        1.000        0.0000   \n",
       "2  10/29/2019 22:56         0.000         0.211        0.789       -0.3400   \n",
       "3  10/29/2019 22:56         0.000         0.202        0.798       -0.5859   \n",
       "4  10/29/2019 22:56         0.066         0.122        0.812       -0.2732   \n",
       "\n",
       "   mention  https  RT  \n",
       "0        1      0   1  \n",
       "1        1      0   1  \n",
       "2        0      1   0  \n",
       "3        1      0   1  \n",
       "4        0      1   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mention'] = np.where(df['text'].str.contains('@'), 1, 0)\n",
    "df['https'] = np.where(df['text'].str.contains('http'), 1,0)\n",
    "df['RT'] = np.where(df['text'].str.contains('RT'), 1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.766858\n",
       "1    0.233142\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X/Y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop = list(ENGLISH_STOP_WORDS)\n",
    "custom_stop.extend([\"b'RT\",\n",
    "                    \"000\",\n",
    "                    \"x80\",\n",
    "                    \"x82\"\n",
    "                    \"x8f\",\n",
    "                    \"x99\",\n",
    "                    \"x94\",\n",
    "                    \"x98\",\n",
    "                    \"x99m\", \n",
    "                    \"x99s\",\n",
    "                    \"x9d\",\n",
    "                    \"x9f\",\n",
    "                    \"xa5\",\n",
    "                    \"xa6\",\n",
    "                    \"xa6'RT\",\n",
    "                    \"xa6'b'RT\",\n",
    "                    \"xa6'b'\",\n",
    "                    \"xb8\",\n",
    "                    \"xe2\",\n",
    "                    \"xef\",\n",
    "                    \"xf0\",\n",
    "                    \"amp\",\n",
    "                    'angele',\n",
    "                    'angeles',\n",
    "                    \"b'\",\n",
    "                    \"Center\",\n",
    "                    'center',\n",
    "                    'com',\n",
    "                    \"Getty\",\n",
    "                    'getty',\n",
    "                    'gettyfire',\n",
    "                    \"Getty Center\",\n",
    "                    \"GettyFire\",\n",
    "                    \"instagram\"\n",
    "                    \"htpps\",\n",
    "                    \"http\",\n",
    "                    \"nhttp\", \n",
    "                    \"nhttps\",\n",
    "                    'los',\n",
    "                    \"Los Angeles\",\n",
    "                    \"Los Angele\",\n",
    "                    \"Los\", \"Angele\",\n",
    "                    \"outfit\",\n",
    "                    'rt',\n",
    "                    \"taco\",\n",
    "                    \"truck\",\n",
    "                    \"taco truck\",\n",
    "                    \"www\"\n",
    "                    \n",
    "                    \n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "])\n",
    "\n",
    "pipe_2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe_3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('bt', BaggingClassifier())\n",
    "])\n",
    "\n",
    "pipe_4 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipe_ngram = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1_params = {\n",
    "    'tfidf__stop_words': [custom_stop],\n",
    "    'tfidf__max_features': [300, 500, 1000],\n",
    "    'tfidf__min_df': [10, 25, 50],\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'lr__C': [0.001, 0.01, 1]\n",
    "}\n",
    "\n",
    "pipe_2_params = {\n",
    "    'tfidf__stop_words': [custom_stop],\n",
    "    'tfidf__max_features': [300, 500, 1000],\n",
    "    'tfidf__min_df': [10, 25, 50],\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'rf__max_depth' : [None, 1, 2],\n",
    "#     'rf__min_samples_split' : [0.2, 0.4, 1],\n",
    "    \n",
    "}\n",
    "\n",
    "pipe_3_params = {\n",
    "    'tfidf__stop_words': [custom_stop],\n",
    "    'tfidf__max_features': [1500, 1700, 2000],\n",
    "    'tfidf__min_df': [35, 37, 42],\n",
    "    'tfidf__max_df': [0.85, 0.9],\n",
    "    'bt__n_estimators' : [1, 2, 3],\n",
    "    'bt__max_samples' : [1, 2, 3],\n",
    "    'bt__max_features' : [1, 2, 3],\n",
    "}\n",
    "\n",
    "pipe_4_params = {\n",
    "    'tfidf__stop_words': [custom_stop],\n",
    "    'tfidf__max_features': [1500, 1700, 2000],\n",
    "    'tfidf__min_df': [35, 37, 42],\n",
    "    'tfidf__max_df': [0.85, 0.9],\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'knn__leaf_size': [20, 30, 50],\n",
    "#     'knn__p': [2, 3, 4],\n",
    "}\n",
    "\n",
    "param_ngram = {\n",
    "    'cvec__stop_words': [custom_stop],\n",
    "    'cvec__ngram_range': [(2,3), (3,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_1 completed\n",
      "gs_2 completed\n",
      "gs_3 completed\n",
      "gs_4 completed\n",
      "n_gram completed\n"
     ]
    }
   ],
   "source": [
    "gs_1 = GridSearchCV(pipe_1,\n",
    "                   pipe_1_params,\n",
    "                   cv = 5,\n",
    "                   verbose = 1,\n",
    "                   n_jobs=-1)\n",
    "print('gs_1 completed')\n",
    "\n",
    "gs_2 = GridSearchCV(pipe_2,\n",
    "                   pipe_2_params,\n",
    "                   cv = 5,\n",
    "                   verbose = 1,\n",
    "                   n_jobs=-1)\n",
    "print('gs_2 completed')\n",
    "\n",
    "gs_3 = GridSearchCV(pipe_3,\n",
    "                   pipe_3_params,\n",
    "                   cv = 5,\n",
    "                   verbose = 1,\n",
    "                   n_jobs=-1)\n",
    "print('gs_3 completed')\n",
    "\n",
    "gs_4 = GridSearchCV(pipe_4,\n",
    "                   pipe_4_params,\n",
    "                   cv = 5,\n",
    "                   verbose = 1,\n",
    "                   n_jobs=-1)\n",
    "print('gs_4 completed')\n",
    "\n",
    "gs_n_gram = GridSearchCV(pipe_ngram,\n",
    "                        param_ngram,\n",
    "                        cv = 5,\n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1)\n",
    "print('n_gram completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_1 best train score: 0.9140765827279183. gs_1 best test score: 0.9116827789611667. The best train model from this grid search is Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=0.7, max_features=1000,\n",
      "                                 min_df=10, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=['cant', 'name', 'whereby',\n",
      "                                             'everywhere', 'whenever', 'or',\n",
      "                                             'to...\n",
      "                                 strip_accents=None, sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False).\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  3.9min finished\n",
      "C:\\Users\\Brianna Lytle\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_2 best train score: 0.9155514284153602. gs_2 best test score: 0.9229886940848763. The best model from this grid search is Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=0.9, max_features=1000,\n",
      "                                 min_df=10, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=['cant', 'name', 'whereby',\n",
      "                                             'everywhere', 'whenever', 'or',\n",
      "                                             'to...\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=None,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=10, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2430 out of 2430 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_3 best train score: 0.7697055771016551. gs_3 best test score: 0.766835982303785. The best model from this grid search is Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=0.85, max_features=1700,\n",
      "                                 min_df=35, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=['cant', 'name', 'whereby',\n",
      "                                             'everywhere', 'whenever', 'or',\n",
      "                                             't...\n",
      "                                             'see', 'six', ...],\n",
      "                                 strip_accents=None, sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('bt',\n",
      "                 BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "                                   bootstrap_features=False, max_features=3,\n",
      "                                   max_samples=2, n_estimators=1, n_jobs=None,\n",
      "                                   oob_score=False, random_state=None,\n",
      "                                   verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_4 best train score: 0.8821762167476921. gs_4 best test score: 0.8761264951663117. The best model from this grid search is Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=0.85, max_features=1500,\n",
      "                                 min_df=42, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=['cant', 'name', 'whereby',\n",
      "                                             'everywhere', 'whenever', 'or',\n",
      "                                             't...\n",
      "                                             'anyway', 'than', 'fifty', 'had',\n",
      "                                             'since', 'ten', 'please', 'over',\n",
      "                                             'see', 'six', ...],\n",
      "                                 strip_accents=None, sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=20,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=None, n_neighbors=3, p=2,\n",
      "                                      weights='uniform'))],\n",
      "         verbose=False)\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_n_gram best train score: 0.8668268968154258. gs_n_gram best test score 0.8700639029985253. The best model from this grid search is Pipeline(memory=None,\n",
      "         steps=[('cvec',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(2, 3), preprocessor=None,\n",
      "                                 stop_words=['cant', 'name', 'whereby',\n",
      "                                             'everywhere', 'whenever', 'or',\n",
      "                                             'to', 'here', 'her', 'almost',\n",
      "                                             'inter...\n",
      "                                             'see', 'six', ...],\n",
      "                                 strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "gs_1.fit(X_train, y_train)\n",
    "print(f'gs_1 best train score: {gs_1.best_score_}. gs_1 best test score: {gs_1.best_estimator_.score(X_test, y_test)}. The best train model from this grid search is {gs_1.best_estimator_}.')\n",
    "\n",
    "gs_2.fit(X_train, y_train)\n",
    "print(f'gs_2 best train score: {gs_2.best_score_}. gs_2 best test score: {gs_2.best_estimator_.score(X_test, y_test)}. The best model from this grid search is {gs_2.best_estimator_}')\n",
    "\n",
    "gs_3.fit(X_train, y_train)\n",
    "print(f'gs_3 best train score: {gs_3.best_score_}. gs_3 best test score: {gs_3.best_estimator_.score(X_test, y_test)}. The best model from this grid search is {gs_3.best_estimator_}')\n",
    "\n",
    "gs_4.fit(X_train, y_train)\n",
    "print(f'gs_4 best train score: {gs_4.best_score_}. gs_4 best test score: {gs_4.best_estimator_.score(X_test, y_test)}. The best model from this grid search is {gs_4.best_estimator_}')\n",
    "\n",
    "gs_n_gram.fit(X_train, y_train)\n",
    "print(f'gs_n_gram best train score: {gs_n_gram.best_score_}. gs_n_gram best test score {gs_n_gram.best_estimator_.score(X_test, y_test)}. The best model from this grid search is {gs_n_gram.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC Cuve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
