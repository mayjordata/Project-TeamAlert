{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprossesing & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook consists of various classification models to predict whether a tweet is related to an emergency situation or not during a wildfire. The goal is to choose best model that will generalize the information on unseen data with the highest accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have combined post-fire Twitter scrape files from Tick Fire, Saddleridge Fire, Kincade Fire, Maria Fire, Colorado fire occured in 2019. We have labeled tweets based on relevance to a natural disaster and combined them with pre-fire tweets within the same location to get 70/30 ratio of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "labeled_df = pd.read_csv('./data/combined_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sia_positive</th>\n",
       "      <th>sia_negative</th>\n",
       "      <th>sia_neutral</th>\n",
       "      <th>sia_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @JulianCastro: My grandmother was a domesti...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @MayorOfLA: #GettyFire update | 8AM:\\n\\n- 5...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Getty Fire Ignited by Power Line in Sepulveda ...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @latimes: In an ominous new warning, the Na...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Arson investigators from the Los Angeles Fire ...</td>\n",
       "      <td>10/29/2019 22:56</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.812</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  RT @JulianCastro: My grandmother was a domesti...   \n",
       "1       1  RT @MayorOfLA: #GettyFire update | 8AM:\\n\\n- 5...   \n",
       "2       1  Getty Fire Ignited by Power Line in Sepulveda ...   \n",
       "3       1  RT @latimes: In an ominous new warning, the Na...   \n",
       "4       1  Arson investigators from the Los Angeles Fire ...   \n",
       "\n",
       "               time  sia_positive  sia_negative  sia_neutral  sia_compound  \n",
       "0  10/29/2019 22:56         0.000         0.000        1.000        0.0000  \n",
       "1  10/29/2019 22:56         0.000         0.000        1.000        0.0000  \n",
       "2  10/29/2019 22:56         0.000         0.211        0.789       -0.3400  \n",
       "3  10/29/2019 22:56         0.000         0.202        0.798       -0.5859  \n",
       "4  10/29/2019 22:56         0.066         0.122        0.812       -0.2732  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target            int64\n",
       "text             object\n",
       "time             object\n",
       "sia_positive    float64\n",
       "sia_negative    float64\n",
       "sia_neutral     float64\n",
       "sia_compound    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18719\n",
       "1     5691\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target          0\n",
       "text            0\n",
       "time            0\n",
       "sia_positive    0\n",
       "sia_negative    0\n",
       "sia_neutral     0\n",
       "sia_compound    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.766858\n",
       "1    0.233142\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop = list(ENGLISH_STOP_WORDS)\n",
    "custom_stop.extend([\"b'RT\", \"xe2\", \"x80\", \"x99\", \"xf0\", \"htpps\", \"xa6\", \"x9f\", \"Getty Center\", \"Los Angeles\",\n",
    "                    \"Los Angele\", \"Getty\", \"x99m\", \"x99s\", \"Los\", \"Angele\", \"taco truck\", \"outfit\", \"taco\", \"truck\",\n",
    "                   \"http\", \"https\", \"x94\", \"xa5\", \"nhttp\", \"nhttps\", \"b'\", \"Center\", \"amp\", \"GettyFire\", \"RT\", \"www\",\n",
    "                   \"instagram\", \"xa6'b'RT\", \"xa6'b'\", \"xa6'RT\", \"xb8\", \"x9d\", \"xef\", \"x8f\", 'http','colorado','co',\n",
    "                    'springs','waldo','canyon','cofire','rt','boulder','waldocanyonfire', 'highparkfire','denverpost',\n",
    "                    'denver','colo', 'tickfire', 'kincade', 'tick', 'kincadefire', 'getty', 'mariafire', 'saddleridge', \n",
    "                    'angele', 'angeles', 'center', 'gettyfire', 'los', 'sonoma', 'sonoma county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to clean text from html tags, non-leters, english stop words, custom stop words\n",
    "\n",
    "def cleanup_lemmatize_text(document):\n",
    "    # remove HTML\n",
    "    text = BeautifulSoup(document).get_text()\n",
    "    # remove non-letter characters\n",
    "    letters = re.sub(\"[^a-zA-Z]\", \" \", document)    \n",
    "    # all words lower case\n",
    "    words = letters.lower().split()\n",
    "    # remove stop words (english + custom)\n",
    "    stops = set(custom_stop)\n",
    "    clean_words = [word for word in words if word not in stops]\n",
    "    # lemmatize cleaned up words\n",
    "    lem_clean_words = [lemmatizer.lemmatize(token) for token in clean_words]\n",
    "    \n",
    "    # returned the cleand up string\n",
    "    return(\" \".join(clean_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty list to hold the clean text\n",
    "clean_text = []\n",
    "\n",
    "for text in labeled_df['text']:\n",
    "#     convert title to words, then append to clean_text list\n",
    "   clean_text.append(cleanup_lemmatize_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24410"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df['text'] = clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression / Count Vectorizer (Only Text)\n",
    "- Logistic Regression / Count Vectorizer (Text & Sentiment Scores)\n",
    "- Logistic Regression / Tfidf Vectorizer (Text & Sentiment Scores)  \n",
    "- Random Forest / Count Vectorizer (Only Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - LR and CVEC (Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features variable(s) with only text column\n",
    "X = labeled_df['text']\n",
    "\n",
    "# define target variable\n",
    "y = labeled_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into the training and testing sets\n",
    "# set a random state for reproducibility \n",
    "# stratify y to combat slightly unbalanced classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.766882\n",
       "1    0.233118\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline accuracy on test data\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer (transformer) & LogisticRegression (estimator)\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "        ('cvec', CountVectorizer(stop_words=custom_stop, max_features=120, ngram_range=(1,2))),\n",
    "        ('logreg', LogisticRegression(solver = 'lbfgs'))\n",
    "])\n",
    "\n",
    "pipe1_params = {\n",
    "  #  'cvec__max_features': [1200, 1800, 2000, 2500],\n",
    "  #  'cvec__stop_words': ['custom_stop'],\n",
    "  #  'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__min_df': [50, 100, 200],\n",
    "    'cvec__max_df': [.55, .75, .85],\n",
    " #   'cvec__strip_accents': ['ascii'],\n",
    "  #  'logreg__penalty': ['l1', 'l2'],\n",
    "  #  'logreg__C': [2, 2.5, 3]\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(pipe1,  # object to be optimized\n",
    "                   pipe1_params, # parameter values to be searched\n",
    "                   cv=5, # 5 folds\n",
    "                   verbose = 1,\n",
    "             #      n_jobs = -1\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=120,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=['not',\n",
       "                                                                    'onto',\n",
       "                                                                    'part',\n",
       "                                                                    'often'...\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'cvec__max_df': [0.55, 0.75, 0.85],\n",
       "                         'cvec__min_df': [50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit gridsearch CV to train data\n",
    "gs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888039623333741"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best score\n",
    "gs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.55, 'cvec__min_df': 100}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "gs1_model = gs1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Train score: 0.8922587746117158\n",
      "Model_1 Test score: 0.8848063555114201\n"
     ]
    }
   ],
   "source": [
    "# Score best model on train set\n",
    "print(f\"Model_1 Train score: {gs1_model.score(X_train, y_train)}\")\n",
    "# Score best model on test set\n",
    "print(f\"Model_1 Test score: {gs1_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds =gs1_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8708     happy lightning mcqueen day apparently cars la...\n",
       "6173     b preevergreen bf aries sun just setting build...\n",
       "18558               artistcouture slid dms earlier morning\n",
       "13741                                u long wow queue time\n",
       "14541    saturnawards tallshipprods outlander starz sta...\n",
       "                               ...                        \n",
       "6022     b lafdchief following orders cooperating helps...\n",
       "3910     b week started bang amazing projects worked co...\n",
       "4498     b country running santa clarita threatening ho...\n",
       "20871    promises promises kept thank potus making word...\n",
       "7882                                     deserves u dallas\n",
       "Name: text, Length: 8056, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5972,  206],\n",
       "       [ 722, 1156]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix\n",
    "confusion_matrix(y_test, # True values\n",
    "                 preds)  # Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TN</td>\n",
       "      <td>5972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FP</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FN</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TP</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Count\n",
       "TN   5972\n",
       "FP    206\n",
       "FN    722\n",
       "TP   1156"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test,preds).ravel(), index=['TN', 'FP', 'FN', 'TP'], \n",
    "                      columns=['Count'])\n",
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = gs1_model.named_steps['cvec'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1_coefs = gs1_model.named_steps['logreg'].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = dict(zip(text_features, gs1_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame(coef_dict.items(), columns=['text_feature', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>3.733780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>evacuations</td>\n",
       "      <td>3.325012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>2.826109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>homes</td>\n",
       "      <td>2.818517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>acres</td>\n",
       "      <td>2.676426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>brush</td>\n",
       "      <td>2.482233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>smoke</td>\n",
       "      <td>2.409133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>near</td>\n",
       "      <td>2.378743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>winds</td>\n",
       "      <td>2.358835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>santa</td>\n",
       "      <td>2.282188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>county</td>\n",
       "      <td>2.247383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>safe</td>\n",
       "      <td>2.116550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>update</td>\n",
       "      <td>2.108414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>wind</td>\n",
       "      <td>2.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>country</td>\n",
       "      <td>1.996693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>power</td>\n",
       "      <td>1.976851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>california</td>\n",
       "      <td>1.955112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>1.852910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>park</td>\n",
       "      <td>1.793491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>rd</td>\n",
       "      <td>1.765512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>firefighters</td>\n",
       "      <td>1.680177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>report</td>\n",
       "      <td>1.610668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>burning</td>\n",
       "      <td>1.591573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>area</td>\n",
       "      <td>1.546040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>san</td>\n",
       "      <td>1.494479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>season</td>\n",
       "      <td>1.481862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>live</td>\n",
       "      <td>1.473585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>news</td>\n",
       "      <td>1.467965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>house</td>\n",
       "      <td>1.385179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>xe xa</td>\n",
       "      <td>1.101886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>fires</td>\n",
       "      <td>1.015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>home</td>\n",
       "      <td>0.944450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ca</td>\n",
       "      <td>0.901265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>warning</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>pm</td>\n",
       "      <td>0.661407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>help</td>\n",
       "      <td>0.500020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>red</td>\n",
       "      <td>0.489275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>school</td>\n",
       "      <td>0.484668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>high</td>\n",
       "      <td>0.384029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>pic</td>\n",
       "      <td>0.364765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>right</td>\n",
       "      <td>0.358328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>xe</td>\n",
       "      <td>0.333702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>th</td>\n",
       "      <td>0.311869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>new</td>\n",
       "      <td>0.304323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>xa</td>\n",
       "      <td>0.275519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>night</td>\n",
       "      <td>0.245337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>going</td>\n",
       "      <td>0.242735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>tonight</td>\n",
       "      <td>0.219349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>video</td>\n",
       "      <td>0.206565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>la</td>\n",
       "      <td>0.196602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_feature      coef\n",
       "20     evacuation  3.733780\n",
       "21    evacuations  3.325012\n",
       "106      wildfire  2.826109\n",
       "38          homes  2.818517\n",
       "0           acres  2.676426\n",
       "6           brush  2.482233\n",
       "83          smoke  2.409133\n",
       "58           near  2.378743\n",
       "109         winds  2.358835\n",
       "78          santa  2.282188\n",
       "14         county  2.247383\n",
       "75           safe  2.116550\n",
       "97         update  2.108414\n",
       "108          wind  2.017621\n",
       "13        country  1.996693\n",
       "69          power  1.976851\n",
       "9      california  1.955112\n",
       "107     wildfires  1.852910\n",
       "64           park  1.793491\n",
       "70             rd  1.765512\n",
       "23   firefighters  1.680177\n",
       "73         report  1.610668\n",
       "7         burning  1.591573\n",
       "1            area  1.546040\n",
       "77            san  1.494479\n",
       "81         season  1.481862\n",
       "49           live  1.473585\n",
       "61           news  1.467965\n",
       "40          house  1.385179\n",
       "114         xe xa  1.101886\n",
       "24          fires  1.015332\n",
       "37           home  0.944450\n",
       "8              ca  0.901265\n",
       "102       warning  0.789062\n",
       "68             pm  0.661407\n",
       "35           help  0.500020\n",
       "72            red  0.489275\n",
       "80         school  0.484668\n",
       "36           high  0.384029\n",
       "66            pic  0.364765\n",
       "74          right  0.358328\n",
       "113            xe  0.333702\n",
       "87             th  0.311869\n",
       "60            new  0.304323\n",
       "111            xa  0.275519\n",
       "62          night  0.245337\n",
       "29          going  0.242735\n",
       "93        tonight  0.219349\n",
       "99          video  0.206565\n",
       "45             la  0.196602"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive coefficients\n",
    "coef_df.sort_values('coef', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>com</td>\n",
       "      <td>-3.529315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>lmao</td>\n",
       "      <td>-1.865128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>igshid</td>\n",
       "      <td>-1.809033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>twitter com</td>\n",
       "      <td>-1.706517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>lol</td>\n",
       "      <td>-1.688368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>years</td>\n",
       "      <td>-1.354208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>happy</td>\n",
       "      <td>-1.333582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>ll</td>\n",
       "      <td>-1.286526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>make</td>\n",
       "      <td>-1.235769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>let</td>\n",
       "      <td>-1.130742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>yes</td>\n",
       "      <td>-1.122082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>-1.085378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>come</td>\n",
       "      <td>-1.054027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>life</td>\n",
       "      <td>-1.037629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>love</td>\n",
       "      <td>-1.032071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>did</td>\n",
       "      <td>-0.872071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>good</td>\n",
       "      <td>-0.871340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>im</td>\n",
       "      <td>-0.862703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>got</td>\n",
       "      <td>-0.861854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ass</td>\n",
       "      <td>-0.830493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>really</td>\n",
       "      <td>-0.727144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>feel</td>\n",
       "      <td>-0.704292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>gonna</td>\n",
       "      <td>-0.695601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>twitter</td>\n",
       "      <td>-0.682082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>california com</td>\n",
       "      <td>-0.679299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>shit</td>\n",
       "      <td>-0.669544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>wait</td>\n",
       "      <td>-0.619517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>pic twitter</td>\n",
       "      <td>-0.610296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>xf xa</td>\n",
       "      <td>-0.606676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>don</td>\n",
       "      <td>-0.543633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>year</td>\n",
       "      <td>-0.516163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>team</td>\n",
       "      <td>-0.496215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>friends</td>\n",
       "      <td>-0.496204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>trying</td>\n",
       "      <td>-0.469902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>didn</td>\n",
       "      <td>-0.468116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>like</td>\n",
       "      <td>-0.464445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>great</td>\n",
       "      <td>-0.436669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>fuck</td>\n",
       "      <td>-0.415556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>better</td>\n",
       "      <td>-0.399522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>want</td>\n",
       "      <td>-0.368676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>ve</td>\n",
       "      <td>-0.361540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>man</td>\n",
       "      <td>-0.359623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>xb</td>\n",
       "      <td>-0.354032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>way</td>\n",
       "      <td>-0.350346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>said</td>\n",
       "      <td>-0.346549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>damn</td>\n",
       "      <td>-0.338373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>thank</td>\n",
       "      <td>-0.312448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>big</td>\n",
       "      <td>-0.297672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>stop</td>\n",
       "      <td>-0.278704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>think</td>\n",
       "      <td>-0.267756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_feature      coef\n",
       "11              com -3.529315\n",
       "51             lmao -1.865128\n",
       "41           igshid -1.809033\n",
       "96      twitter com -1.706517\n",
       "52              lol -1.688368\n",
       "118           years -1.354208\n",
       "34            happy -1.333582\n",
       "50               ll -1.286526\n",
       "56             make -1.235769\n",
       "46              let -1.130742\n",
       "119             yes -1.122082\n",
       "3              best -1.085378\n",
       "12             come -1.054027\n",
       "47             life -1.037629\n",
       "55             love -1.032071\n",
       "17              did -0.872071\n",
       "31             good -0.871340\n",
       "42               im -0.862703\n",
       "32              got -0.861854\n",
       "2               ass -0.830493\n",
       "71           really -0.727144\n",
       "22             feel -0.704292\n",
       "30            gonna -0.695601\n",
       "95          twitter -0.682082\n",
       "10   california com -0.679299\n",
       "82             shit -0.669544\n",
       "100            wait -0.619517\n",
       "67      pic twitter -0.610296\n",
       "116           xf xa -0.606676\n",
       "19              don -0.543633\n",
       "117            year -0.516163\n",
       "86             team -0.496215\n",
       "25          friends -0.496204\n",
       "94           trying -0.469902\n",
       "18             didn -0.468116\n",
       "48             like -0.464445\n",
       "33            great -0.436669\n",
       "26             fuck -0.415556\n",
       "4            better -0.399522\n",
       "101            want -0.368676\n",
       "98               ve -0.361540\n",
       "57              man -0.359623\n",
       "112              xb -0.354032\n",
       "104             way -0.350346\n",
       "76             said -0.346549\n",
       "15             damn -0.338373\n",
       "88            thank -0.312448\n",
       "5               big -0.297672\n",
       "85             stop -0.278704\n",
       "90            think -0.267756"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative coefficients\n",
    "coef_df.sort_values('coef').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gs1_model, open('model.p', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.55,\n",
       "                                 max_features=120, min_df=100,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=['not', 'onto', 'part', 'often',\n",
       "                                             'whenever', 'ever', 'etc', 'alone',\n",
       "                                             'where', 'system', 'fifty'...\n",
       "                                             'me', 'sincere', 'their', 'nobody', ...],\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_pickle = pickle.load(open('model.p', 'rb'))\n",
    "model_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model with sample words\n",
    "model_from_pickle.predict(np.array(['fire wind help']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - LR and CVEC (Text & Numeric Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X and y\n",
    "# this time we will include some numeric features to see their impact\n",
    "X_union = labeled_df[['text', 'sia_positive', 'sia_negative','sia_neutral', 'sia_compound']]\n",
    "y_union = labeled_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_union_train, X_union_test, y_union_train, y_union_test = train_test_split(X_union, y_union, test_size=0.33, \n",
    "                                                                               stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions to group features based on data type\n",
    "def get_text(data):\n",
    "    return data['text']\n",
    "\n",
    "def get_numeric(data):\n",
    "    return data[['sia_positive', 'sia_negative','sia_neutral', 'sia_compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function transformer for text features\n",
    "get_text_tf = FunctionTransformer(get_text, validate=False)\n",
    "# create function transformer for numeric features\n",
    "get_numeric_tf = FunctionTransformer(get_numeric, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new pipeline\n",
    "pipe2 = Pipeline([\n",
    "    # feature union\n",
    "    ('union', FeatureUnion([\n",
    "        # numeric\n",
    "        ('numeric', get_numeric_tf),\n",
    "        # text\n",
    "        ('text', Pipeline([\n",
    "            # extract text\n",
    "            ('selector', get_text_tf),\n",
    "            # vectorize\n",
    "            ('cvec', CountVectorizer(stop_words=custom_stop, max_features=1200, ngram_range=(1,2)))\n",
    "        ]))\n",
    "    ])),\n",
    "    # model\n",
    "    ('logreg', LogisticRegression(penalty='l2', C=1, solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipe2_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(pipe2, pipe2_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('union',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('numeric',\n",
       "                                                                        FunctionTransformer(accept_sparse=False,\n",
       "                                                                                            check_inverse=True,\n",
       "                                                                                            func=<function get_numeric at 0x0000018BE814E798>,\n",
       "                                                                                            inv_kw_args=None,\n",
       "                                                                                            inverse_func=None,\n",
       "                                                                                            kw_args=None,\n",
       "                                                                                            pass_y='deprecated',\n",
       "                                                                                            validate=False)),\n",
       "                                                                       ('text',...\n",
       "                                        LogisticRegression(C=1,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None, param_grid={}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X_union_train, y_union_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2 Train score: 0.9356120826709062\n",
      "Model_2 Test score: 0.9152184707050646\n"
     ]
    }
   ],
   "source": [
    "# Score the model on train set\n",
    "print(f\"Model_2 Train score: {gs2.score(X_union_train, y_union_train)}\")\n",
    "# Score the model on test set\n",
    "print(f\"Model_2 Test score: {gs2.score(X_union_test, y_union_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - LR & Tfidf (Text & Numeric Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new pipeline\n",
    "pipe3 = Pipeline([\n",
    "    # feature union\n",
    "    ('union', FeatureUnion([\n",
    "        # numeric\n",
    "        ('numeric', get_numeric_tf),\n",
    "        # text\n",
    "        ('text', Pipeline([\n",
    "            # extract text\n",
    "            ('selector', get_text_tf),\n",
    "            # vectorize\n",
    "            ('tvec', TfidfVectorizer(stop_words=custom_stop, max_features=1200, \n",
    "                                     ngram_range=(1,2), min_df=100, max_df=.75))\n",
    "        ]))\n",
    "    ])),\n",
    "    # model\n",
    "    ('logreg', LogisticRegression(penalty='l1', C=1, solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "pipe3_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3 = GridSearchCV(pipe3, pipe3_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('union',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('numeric',\n",
       "                                                                        FunctionTransformer(accept_sparse=False,\n",
       "                                                                                            check_inverse=True,\n",
       "                                                                                            func=<function get_numeric at 0x0000018BE814E798>,\n",
       "                                                                                            inv_kw_args=None,\n",
       "                                                                                            inverse_func=None,\n",
       "                                                                                            kw_args=None,\n",
       "                                                                                            pass_y='deprecated',\n",
       "                                                                                            validate=False)),\n",
       "                                                                       ('text',...\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l1',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='liblinear',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None, param_grid={}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.fit(X_union_train, y_union_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_3 Train score: 0.9022869022869023\n",
      "Model_3 Test score: 0.8933714001986097\n"
     ]
    }
   ],
   "source": [
    "# Score the model on train set\n",
    "print(f\"Model_3 Train score: {gs3.score(X_union_train, y_union_train)}\")\n",
    "# Score the model on test set\n",
    "print(f\"Model_3 Test score: {gs3.score(X_union_test, y_union_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 - Random Forest & CVEC (Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer (transformer) & RandomForestClassifier (estimator)\n",
    "\n",
    "pipe4 = Pipeline([\n",
    "        ('cvec', CountVectorizer(stop_words=custom_stop, max_features=1200, ngram_range=(1,2))),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe4_params = {\n",
    "  #  'cvec__max_features': [1200, 1800, 2000, 2500],\n",
    "  #  'cvec__stop_words': ['custom_stop'],\n",
    "  #  'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'cvec__min_df': [50, 70],\n",
    "    'cvec__max_df': [.55, .75],\n",
    "    'rf__n_estimators': [10, 12],\n",
    "    'rf__max_depth': [None, 5, 6],\n",
    "    'rf__max_features': [None, 30],\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(pipe4,  # object to be optimized\n",
    "                   pipe4_params, # parameter values to be searched\n",
    "                   cv=5, # 5 folds\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=1200,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=['not',\n",
       "                                                                    'onto',\n",
       "                                                                    'part',\n",
       "                                                                    'often...\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.55, 0.75], 'cvec__min_df': [50, 70],\n",
       "                         'rf__max_depth': [None, 5, 6],\n",
       "                         'rf__max_features': [None, 30],\n",
       "                         'rf__n_estimators': [10, 12]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.55,\n",
       " 'cvec__min_df': 50,\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': None,\n",
       " 'rf__n_estimators': 12}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894826953650483"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_4 Train score: 0.9706493824140883\n",
      "Model_4 Test score: 0.8938679245283019\n"
     ]
    }
   ],
   "source": [
    "# Score the model on train set\n",
    "print(f\"Model_4 Train score: {gs4.score(X_train, y_train)}\")\n",
    "# Score the model on test set\n",
    "print(f\"Model_4 Test score: {gs4.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5 - Random Forest & Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer (transformer) & RandomForestClassifier (estimator)\n",
    "\n",
    "pipe5 = Pipeline([\n",
    "        ('tvec', CountVectorizer(stop_words=custom_stop, max_features=1200, ngram_range=(1,2))),\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe5_params = {\n",
    "  #  'cvec__max_features': [1200, 1800, 2000, 2500],\n",
    "  #  'cvec__stop_words': ['custom_stop'],\n",
    "  #  'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'tvec__min_df': [50, 70],\n",
    "    'tvec__max_df': [.55, .75],\n",
    "    'rf__n_estimators': [10, 12],\n",
    "    'rf__max_depth': [None, 5, 6],\n",
    "    'rf__max_features': [None, 30, \"sqrt\"],\n",
    "}\n",
    "\n",
    "gs5 = GridSearchCV(pipe5,  # object to be optimized\n",
    "                   pipe5_params, # parameter values to be searched\n",
    "                   cv=5, # 5 folds\n",
    "                   verbose = 1,\n",
    "                   n_jobs = -1\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=1200,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=['not',\n",
       "                                                                    'onto',\n",
       "                                                                    'part',\n",
       "                                                                    'often...\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'rf__max_depth': [None, 5, 6],\n",
       "                         'rf__max_features': [None, 30, 'sqrt'],\n",
       "                         'rf__n_estimators': [10, 12],\n",
       "                         'tvec__max_df': [0.55, 0.75],\n",
       "                         'tvec__min_df': [50, 70]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961110431698667"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs5.best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
